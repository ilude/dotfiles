# Academic Research: LLM Agent Security (2023-2025)

> **Research Date**: 2025-01-29
> **Focus**: Academic papers on securing tool-augmented LLM agents
> **Sources**: arxiv.org, ACL, ICLR

---

## 1. Comprehensive Surveys and Frameworks

### Survey Papers

| Paper | Year | Key Focus |
|-------|------|-----------|
| [Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges](https://arxiv.org/html/2510.23883v1) | 2025 | Comprehensive taxonomy of threats, benchmarks, defense strategies |
| [A Survey on Agentic Security: Applications, Threats and Defenses](https://www.arxiv.org/pdf/2510.06445) | 2025 | Hardening techniques and countermeasures for agentic systems |
| [A Survey of LLM-Driven AI Agent Communication](https://arxiv.org/html/2506.19676v4) | 2025 | Protocol security (MCP, A2A), inter-agent communication risks |
| [On Protecting the Data Privacy of LLMs: A Survey](https://arxiv.org/abs/2403.05156) | 2024 | Privacy threats taxonomy, protection mechanisms at various stages |

**Practical Takeaway**: These surveys provide comprehensive threat models. Use them to identify which attack vectors are relevant to your specific agent architecture.

---

## 2. Prompt Injection Defense

### Detection-Based Approaches

| Paper | Technique | Results |
|-------|-----------|---------|
| [Attention Tracker](https://arxiv.org/abs/2411.00348) | Training-free attention pattern analysis | 10% AUROC improvement, works on small LLMs |
| [PromptArmor](https://arxiv.org/html/2507.15219v1) | Guardrail that detects and removes injected prompts | <1% false positive/negative rates on AgentDojo |
| [DataSentinel](https://arxiv.org/html/2411.00459) | Game-theoretic fine-tuning for detection | State-of-the-art detection, improved generalization |

### Prevention-Based Approaches

| Paper | Technique | Results |
|-------|-----------|---------|
| [A Multi-Agent LLM Defense Pipeline](https://arxiv.org/html/2509.14285v1) | Multi-agent pipeline with 55 attack categories | 100% mitigation across all tested scenarios |
| [Defense Against IPI via Tool Result Parsing](https://arxiv.org/html/2601.04795v1) | Sanitize tool outputs before feeding to agent | Addresses MCP-based attacks |
| [Defending with DefensiveTokens](https://arxiv.org/html/2507.07974v1) | Insert defensive tokens into prompts | Lightweight, minimal overhead |

**Practical Takeaways**:
- **Perplexity-based detection**: High perplexity scores indicate injected sequences disrupting semantic coherence
- **Layered defense**: Combine input sanitization + output filtering + attention monitoring
- **Tool boundary firewalls**: Minimizer (removes unnecessary data from tool inputs) + Sanitizer (filters tool responses)

---

## 3. Privilege Control and Access Control

| Paper | Approach | Results |
|-------|----------|---------|
| [Progent: Programmable Privilege Control](https://arxiv.org/html/2504.11703v1/) | Policy-based tool access restriction | ASR reduced from 70.3% to 7.3% (auto) or 0% (manual policies) |
| [SEAgent: Mandatory Access Control](https://arxiv.org/html/2601.11893v1) | MAC framework against privilege escalation | Defends against confused deputy attacks |
| [MiniScope: Least Privilege Framework](https://arxiv.org/pdf/2512.11147) | Permission hierarchies based on OAuth scopes | Structured sensitivity-based tool grouping |
| [Prompt Flow Integrity (PFI)](https://arxiv.org/html/2503.15547v2) | Isolate trusted/untrusted agents | Adapts system security principles to LLM agents |

**Practical Takeaways**:
- **Least privilege by default**: Only grant tools necessary for the specific task
- **Programmable policies**: Use Progent-style declarative policies that can be auto-generated by LLMs but confirmed by users
- **Trust boundaries**: Separate processing of trusted (user input) vs untrusted (tool responses) data

---

## 4. Sandboxing and Execution Isolation

| Paper | Approach | Results |
|-------|----------|---------|
| [CELLMATE: Sandboxing Browser AI Agents](https://www.arxiv.org/pdf/2512.12594) | Per-website access control, agent sitemap abstraction | Collaborative permission model for all stakeholders |
| [AgentBox/Securing AI Agent Execution](https://arxiv.org/html/2510.21236v1) | Container-based sandbox for MCP servers | Minimal overhead (few hundred ms per container startup) |
| [Fault-Tolerant Sandboxing for AI Coding Agents](https://arxiv.org/pdf/2512.12806) | Transactional approach with rollback | 100% interception rate, 100% rollback success, 14.5% overhead |
| [Security of AI Agents](https://arxiv.org/pdf/2406.08689) | Sandbox configuration for BashAgent | 100% defense against LLM-generated attacks when properly configured |

**Practical Takeaways**:
- **Alignment is insufficient**: Even aligned models (GPT-3.5-turbo) fail to reject malicious intent in agent contexts
- **Container isolation**: Startup cost is amortized across LLM roundtrips (which are already slow)
- **Transactional execution**: Allow rollback of failed/malicious operations
- **File isolation across sessions**: Prevent data leakage between different agent invocations

---

## 5. Data Leakage Prevention

| Paper | Technique | Key Finding |
|-------|-----------|-------------|
| [LeakSealer](https://arxiv.org/html/2508.00602) | Semi-supervised defense against leakage | Addresses both prompt injection and PII leakage |
| [Privacy-Aware Decoding for RAG](https://arxiv.org/html/2508.03098v1) | Token-level noise injection with RDP accounting | First decoding-time defense for RAG privacy |
| [Information Leakage from Embedding](https://arxiv.org/abs/2405.11916) | Embedding reconstruction defense | Mitigates input reconstruction attacks |
| [Self-Guard](https://arxiv.org/pdf/2505.00976) | Self-monitoring output sanitization | Model detects and filters own sensitive outputs |

**Practical Takeaways**:
- **Output sanitization**: Filter responses before returning to users
- **PII redaction**: Apply at both input and output stages
- **Differential privacy**: Apply DP guarantees in training pipeline for sensitive applications
- **Embedding protection**: Be aware that hidden states can leak input information

---

## 6. Output Filtering and Guardrails

| Paper | Approach | Key Finding |
|-------|----------|-------------|
| [Building Guardrails for LLMs](https://arxiv.org/abs/2402.01822) | Framework for systematic guardrail construction | Advocates multi-disciplinary socio-technical approach |
| [No Free Lunch With Guardrails](https://arxiv.org/html/2504.00441v2) | Theoretical analysis | No guardrail minimizes risk, utility, and usability simultaneously |
| [Wildflare GuardRail Pipeline](https://arxiv.org/html/2502.08142v1) | Detection + grounding + correction pipeline | Fine-tuned specialized models for each stage |
| [RAG Makes Guardrails Unsafe?](https://arxiv.org/html/2510.05310) | Robustness evaluation | Benign documents can alter guardrail judgments 8-11% of the time |

**Practical Takeaways**:
- **Guardrails are modular**: Can be updated independently of the base model
- **Trade-offs exist**: Accept that some utility loss is inevitable for safety
- **RAG context affects guardrails**: Test guardrails with realistic RAG contexts
- **Streaming content monitoring**: [From Judgment to Interference](https://arxiv.org/html/2506.09996v1) shows early stopping of harmful outputs is feasible

---

## 7. Benchmarks for Evaluation

| Benchmark | Focus | Paper |
|-----------|-------|-------|
| [Agent Security Bench (ASB)](https://arxiv.org/pdf/2410.02644v3) | Comprehensive adversarial attacks on agents | ICLR 2025 |
| [InjecAgent](https://aclanthology.org/2024.findings-acl.624/) | Indirect prompt injection in tool-integrated agents | 1,054 test cases, 17 tools, 62 attacker tools |
| [AgentDojo](https://arxiv.org/html/2507.15219v1) | Agent security evaluation | Used by PromptArmor for benchmarking |
| [WASP](https://arxiv.org/pdf/2504.18575) | Web agent security | Prompt injection attacks on web agents |

**Practical Takeaway**: Use ASB and InjecAgent to evaluate your defenses before deployment.

---

## Key Defense Patterns Summary

### Layer 1: Input Sanitization
- Perplexity-based anomaly detection
- Attention pattern analysis (Attention Tracker)
- Prompt armor/detection guardrails

### Layer 2: Privilege Control
- Least privilege tool access (Progent, MiniScope)
- Mandatory access control (SEAgent)
- Trust boundary isolation (PFI)

### Layer 3: Execution Isolation
- Container sandboxing (AgentBox, CELLMATE)
- Session isolation
- Transactional execution with rollback

### Layer 4: Output Filtering
- Content moderation models
- PII redaction
- Self-monitoring (Self-Guard)
- Streaming content monitoring for early stopping

### Layer 5: Continuous Monitoring
- Logging and audit trails
- Anomaly detection on agent behavior
- Rate limiting on sensitive operations

---

## Applicability to Claude Code Hooks

| Academic Approach | Claude Code Hook Implementation |
|-------------------|--------------------------------|
| Perplexity detection | PreToolUse hook analyzing command entropy |
| Privilege control | Tool-specific allow/deny patterns in patterns.yaml |
| Sandboxing | Already uses sandbox; hooks add policy layer |
| Output filtering | PostToolUse hook scanning for sensitive data |
| Trust boundaries | Separate handling of user vs tool-generated content |

---

## Source URLs

- https://arxiv.org/html/2510.23883v1
- https://www.arxiv.org/pdf/2510.06445
- https://arxiv.org/html/2506.19676v4
- https://arxiv.org/abs/2403.05156
- https://arxiv.org/abs/2411.00348
- https://arxiv.org/html/2507.15219v1
- https://arxiv.org/html/2411.00459
- https://arxiv.org/html/2509.14285v1
- https://arxiv.org/html/2601.04795v1
- https://arxiv.org/html/2507.07974v1
- https://arxiv.org/html/2504.11703v1/
- https://arxiv.org/html/2601.11893v1
- https://arxiv.org/pdf/2512.11147
- https://arxiv.org/html/2503.15547v2
- https://www.arxiv.org/pdf/2512.12594
- https://arxiv.org/html/2510.21236v1
- https://arxiv.org/pdf/2512.12806
- https://arxiv.org/pdf/2406.08689
- https://arxiv.org/html/2508.00602
- https://arxiv.org/html/2508.03098v1
- https://arxiv.org/abs/2405.11916
- https://arxiv.org/pdf/2505.00976
- https://arxiv.org/abs/2402.01822
- https://arxiv.org/html/2504.00441v2
- https://arxiv.org/html/2502.08142v1
- https://arxiv.org/html/2510.05310
- https://arxiv.org/html/2506.09996v1
- https://arxiv.org/pdf/2410.02644v3
- https://aclanthology.org/2024.findings-acl.624/
- https://arxiv.org/pdf/2504.18575
